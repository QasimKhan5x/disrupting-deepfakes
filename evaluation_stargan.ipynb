{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JqvqAyqPc9q"
      },
      "source": [
        "## StarGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6MZu9HLRDMW"
      },
      "source": [
        "### Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NLcXEXhSI2H2"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "import torchvision\n",
        "from stargan.data_loader import get_loader\n",
        "from stargan.psolver import Disruptor\n",
        "from stargan.attacks import LinfPGDAttack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WHZJRaCTI2ql"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"Set seed\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-G6bzz-I35F",
        "outputId": "55de641c-179d-4c1a-e201-478579b7a990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(alpha=0.1, attr_path='stargan/data/celeba/list_attr_celeba.txt', batch_size=32, beta1=0.99, beta2=0.999, c2_dim=8, c_dim=5, celeba_crop_size=178, celeba_image_dir='stargan/data/celeba/images', d_conv_dim=64, d_repeat_num=6, dataset='CelebA', detector='xception', detector_path='detection/detector_c23.pth', disable_tensorboard=False, epochs=30, eps=0.05, g_conv_dim=64, g_repeat_num=6, gen_ckpt='stargan/stargan_celeba_128/models/200000-G.ckpt', image_size=128, lambda_cls=1, lambda_gp=10, lambda_rec=10, log_dir='logs', log_step=1, lr=0.0001, mode='train', model_save_dir='model_save_dir', num_workers=48, order=2, outputs_dir='experiment1', rafd_crop_size=256, result_dir='results', resume=False, sample_dir='samples', sample_step=1, seed=0, selected_attrs=['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young'])\n"
          ]
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Model configuration.\n",
        "parser.add_argument('--c_dim', type=int, default=5, help='dimension of domain labels (1st dataset)')\n",
        "parser.add_argument('--c2_dim', type=int, default=8, help='dimension of domain labels (2nd dataset)')\n",
        "parser.add_argument('--celeba_crop_size', type=int, default=178, help='crop size for the CelebA dataset')\n",
        "parser.add_argument('--rafd_crop_size', type=int, default=256, help='crop size for the RaFD dataset')\n",
        "parser.add_argument('--image_size', type=int, default=128, help='image resolution')\n",
        "parser.add_argument('--g_conv_dim', type=int, default=64, help='number of conv filters in the first layer of G')\n",
        "parser.add_argument('--d_conv_dim', type=int, default=64, help='number of conv filters in the first layer of D')\n",
        "parser.add_argument('--g_repeat_num', type=int, default=6, help='number of residual blocks in G')\n",
        "parser.add_argument('--d_repeat_num', type=int, default=6, help='number of strided conv layers in D')\n",
        "parser.add_argument('--lambda_cls', type=float, default=1, help='weight for domain classification loss')\n",
        "parser.add_argument('--lambda_rec', type=float, default=10, help='weight for reconstruction loss')\n",
        "parser.add_argument('--lambda_gp', type=float, default=10, help='weight for gradient penalty')\n",
        "parser.add_argument('--eps', type=float, default=0.05, help='epsilon for perturbation')\n",
        "parser.add_argument('--order', type=int, default=2, help='distance metric')\n",
        "parser.add_argument('--detector', type=str, default='xception', choices=['xception', 'resnet18', 'resnet50'])\n",
        "\n",
        "# Training configuration.\n",
        "parser.add_argument('--seed', type=int, default=0, help='seed for experiments')\n",
        "parser.add_argument('--dataset', type=str, default='CelebA', choices=['CelebA', 'RaFD', 'Both'])\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='mini-batch size')\n",
        "parser.add_argument('--epochs', type=int, default=30, help='number of total epochs for training P')\n",
        "parser.add_argument('--lr', type=float, default=1e-4, help='learning rate for P')\n",
        "parser.add_argument('--beta1', type=float, default=0.99, help='beta1 for Adam optimizer')\n",
        "parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
        "parser.add_argument('--resume', default=False, action='store_true', help='resume training from last epoch')\n",
        "parser.add_argument('--selected_attrs', '--list', nargs='+', help='selected attributes for the CelebA dataset',\n",
        "                    default=['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young'])\n",
        "parser.add_argument('--alpha', type=float, default=0.1, help=\"alpha for gradnorm\")\n",
        "\n",
        "# Miscellaneous.\n",
        "parser.add_argument('--num_workers', type=int, default=48)\n",
        "parser.add_argument('--mode', type=str, default='train', choices=['train', 'test'])\n",
        "parser.add_argument('--disable_tensorboard', action='store_true', default=False)\n",
        "\n",
        "# Directories.\n",
        "parser.add_argument('--outputs_dir', type=str, default='experiment1')\n",
        "parser.add_argument('--gen_ckpt', type=str,\n",
        "                    default='stargan/stargan_celeba_128/models/200000-G.ckpt')\n",
        "parser.add_argument('--detector_path', type=str,\n",
        "                    default='detection/detector_c23.pth')\n",
        "parser.add_argument('--celeba_image_dir', type=str, default='stargan/data/celeba/images')\n",
        "parser.add_argument('--attr_path', type=str, default='stargan/data/celeba/list_attr_celeba.txt')\n",
        "parser.add_argument('--log_dir', type=str, default='logs')\n",
        "parser.add_argument('--model_save_dir', type=str,\n",
        "                    default='model_save_dir')\n",
        "parser.add_argument('--sample_dir', type=str, default='samples')\n",
        "parser.add_argument('--result_dir', type=str, default='results')\n",
        "\n",
        "# Step size.\n",
        "parser.add_argument('--log_step', type=int, default=1)\n",
        "parser.add_argument('--sample_step', type=int, default=1)\n",
        "\n",
        "config = parser.parse_args(args=[])\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-mf8XPCI5Sr"
      },
      "source": [
        "### Instantiate Objects & Define Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "93OVeYSoI9HV"
      },
      "outputs": [],
      "source": [
        "set_seed(config.seed)\n",
        "torch.cuda.set_device(0)\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJlEdzj8I9c0",
        "outputId": "91b1fbd0-e2cd-45f5-a74a-1047bd64c3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished preprocessing the CelebA dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/disruptor/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/disruptor/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Solver for training and testing DeepFake Disruptor\n",
        "config.num_workers = 1\n",
        "config.mode = 'test'\n",
        "config.batch_size = 1\n",
        "# bb_dir = '/home/data/bb_celeba/'\n",
        "\n",
        "celeba_loader = get_loader(config.celeba_image_dir, config.attr_path, config.selected_attrs,\n",
        "                            config.celeba_crop_size, config.image_size, config.batch_size,\n",
        "                            'CelebA', config.mode, config.num_workers)\n",
        "\n",
        "config.detector = \"resnet50\"\n",
        "resnet18 = \"garbage/resnet_18_weights/last.ckpt\"\n",
        "resnet50 = \"garbage/resnet_50_weights/r50.ckpt\"\n",
        "\n",
        "config.detector_path = resnet50\n",
        "\n",
        "solver = Disruptor(config, celeba_loader).cuda()\n",
        "\n",
        "G = solver.G\n",
        "\n",
        "D = solver.D.eval()\n",
        "D.eval()\n",
        "\n",
        "P = solver.P\n",
        "P.eval()\n",
        "P.load_state_dict(torch.load(\"stargan/128/perturbation_models/best.ckpt\", map_location=\"cuda\"))\n",
        "\n",
        "del solver\n",
        "\n",
        "pgd_attack = LinfPGDAttack(model=G, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OrHzzsUzJA9N"
      },
      "outputs": [],
      "source": [
        "def denorm(x):\n",
        "    \"\"\"Convert the range from [-1, 1] to [0, 1].\"\"\"\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp_(0, 1)\n",
        "\n",
        "def get_images_without_attr(celeba_loader, attr, num_images=100, bb=False):\n",
        "    attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
        "    i = 0\n",
        "    for i, attribute in enumerate(attrs):\n",
        "        if attribute == attr:\n",
        "            break\n",
        "    images = []\n",
        "    if bb:\n",
        "        bboxes = []\n",
        "        for x, c, bb in celeba_loader:\n",
        "            # target must not be bald\n",
        "            images.extend(x[(c[:, i] != 1) & (c[:, :3].sum(dim=1) != 0)])\n",
        "            bboxes.extend(bb[(c[:, i] != 1) & (c[:, :3].sum(dim=1) != 0)])\n",
        "            if len(images) >= 100:\n",
        "                images = images[:100]\n",
        "                bboxes = bboxes[:100]\n",
        "                break\n",
        "        bboxes = torch.stack(bboxes)\n",
        "        images = torch.stack(images)\n",
        "        return images, bboxes\n",
        "    else:\n",
        "        for x, c in celeba_loader:\n",
        "            # target must not be bald\n",
        "            images.extend(x[(c[:, i] != 1) & (c[:, :3].sum(dim=1) != 0)])\n",
        "            if len(images) >= 100:\n",
        "                images = images[:100]\n",
        "                break\n",
        "        images = torch.stack(images)\n",
        "        return images\n",
        "\n",
        "def show_images(x):\n",
        "    images = denorm(x.cpu())\n",
        "    grid_img = torchvision.utils.make_grid(images, nrow=10)\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(grid_img.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "glQvpU2qxAvu"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate(x, c):\n",
        "    return G(x, c)[0]\n",
        "\n",
        "def joint_class_attack(x_real, x_fake, c):\n",
        "    x_adv, perturb = pgd_attack.perturb(x_real, x_fake, c)\n",
        "    x_adv = x_real + perturb\n",
        "    return x_adv\n",
        "    \n",
        "@torch.no_grad()\n",
        "def detect(x):\n",
        "    output = D(x)\n",
        "    output = softmax(output, 1)\n",
        "    prediction = output.argmin(1, keepdim=False)\n",
        "    return prediction\n",
        "\n",
        "@torch.no_grad()\n",
        "def perturb(x):\n",
        "    return P(x) + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Yz52Ho-4Zrhx"
      },
      "outputs": [],
      "source": [
        "attribute = \"Black_Hair\"\n",
        "x = get_images_without_attr(celeba_loader, attribute, bb=False)\n",
        "x = x.cuda()\n",
        "c = torch.tensor([1, 0, 0, 0, 0])\n",
        "c = c.tile(100).view(100, 5).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnCFVlgDxFpU"
      },
      "source": [
        "### Qualitative Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "4XzE9EKlxOrY",
        "outputId": "7570cf27-313f-4775-fe04-f2679e3a47db"
      },
      "outputs": [],
      "source": [
        "show_images(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "heSkE5pUxUqY",
        "outputId": "646c8284-8d14-4ea8-f94f-aab1a06cc752"
      },
      "outputs": [],
      "source": [
        "x_fake = generate(x, c)\n",
        "show_images(x_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "7og0O2HyJHGn",
        "outputId": "6168166e-75da-4ea6-cdf3-26a2ba23e764"
      },
      "outputs": [],
      "source": [
        "x_adv = joint_class_attack(x, x_fake, c)\n",
        "show_images(x_adv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "cSEXQN70O-91",
        "outputId": "056ede34-c783-4c6f-bedb-ceec1b5b6df0"
      },
      "outputs": [],
      "source": [
        "x_pert = perturb(x)\n",
        "show_images(x_pert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "zUdGsGPqNdxK",
        "outputId": "e18f32b9-11d9-4b3a-884d-ed6ac08ac53b"
      },
      "outputs": [],
      "source": [
        "x_adv_fake = generate(x_adv, c)\n",
        "show_images(x_adv_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "VklYMk3aOTXm",
        "outputId": "60495dbd-e690-42ba-b03f-b591c2bd3db5"
      },
      "outputs": [],
      "source": [
        "x_pert_fake = generate(x_pert, c)\n",
        "show_images(x_pert_fake)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onMEXEF_xeAP"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qXED_Om1xdqc"
      },
      "outputs": [],
      "source": [
        "def get_l2_distance(x_fake, xp_fake):\n",
        "    B = x_fake.size(0)\n",
        "    x_fake = x_fake.view(B, -1)\n",
        "    xp_fake = xp_fake.view(B, -1)\n",
        "    return torch.linalg.norm(x_fake - xp_fake, dim=1, ord=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "E1Ip4EUORbk9"
      },
      "outputs": [],
      "source": [
        "def get_metrics(x, c):\n",
        "    xp = perturb(x)\n",
        "    x_fake = generate(x, c)\n",
        "    xp_fake = generate(xp, c)\n",
        "    x_adv = joint_class_attack(x, x_fake, c)\n",
        "    x_adv_fake = generate(x_adv, c)\n",
        "    \n",
        "    predicted_real = detect(x).cpu().numpy()\n",
        "    predicted_real_p = detect(xp).cpu().numpy()\n",
        "\n",
        "    predicted_fake = detect(x_fake).cpu().numpy()\n",
        "    predicted_fake_p = detect(xp_fake).cpu().numpy()\n",
        "    predicted_fake_adv = detect(x_adv_fake).cpu().numpy()\n",
        "    \n",
        "    print(\"Success Rate G[x+P(x)]:\", predicted_fake_p.sum() / 100)\n",
        "\n",
        "    y_pred = np.hstack((predicted_real, predicted_fake))\n",
        "    yp_pred = np.hstack((predicted_real_p, predicted_fake_p))\n",
        "    # yp_pred = np.hstack((predicted_real, predicted_fake_p))\n",
        "    yadv_pred = np.hstack((predicted_real, predicted_fake_adv))\n",
        "    y_true = np.hstack((np.ones(100), np.zeros(100)))\n",
        "\n",
        "    report_stargan = classification_report(y_true, y_pred, target_names=[\"fake\", \"real\"])\n",
        "    report_pgd = classification_report(y_true, yadv_pred, target_names=[\"fake\", \"real\"])\n",
        "    report_disruptor = classification_report(y_true, yp_pred, target_names=[\"fake\", \"real\"])\n",
        "\n",
        "    return report_stargan, report_pgd, report_disruptor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "L5vvqkJ7aN-T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success Rate G[x+P(x)]: 0.27\n"
          ]
        }
      ],
      "source": [
        "report_stargan, report_pgd, report_disruptor = get_metrics(x, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfVkuQoaaY0A",
        "outputId": "daca39ac-4fcc-4460-bc45-bdafe3eaee96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.53      0.08      0.14       100\n",
            "        real       0.50      0.93      0.65       100\n",
            "\n",
            "    accuracy                           0.51       200\n",
            "   macro avg       0.52      0.51      0.40       200\n",
            "weighted avg       0.52      0.51      0.40       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(report_stargan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqxqwdT-Ype6",
        "outputId": "8557acc0-0dca-45a7-a8af-ca34f4cad7b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.88      0.53      0.66       100\n",
            "        real       0.66      0.93      0.78       100\n",
            "\n",
            "    accuracy                           0.73       200\n",
            "   macro avg       0.77      0.73      0.72       200\n",
            "weighted avg       0.77      0.73      0.72       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(report_pgd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqERbRoJajDj",
        "outputId": "bfe0496f-5ff5-4517-eafa-2446cd821a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.94      0.73      0.82       100\n",
            "        real       0.78      0.95      0.86       100\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.86      0.84      0.84       200\n",
            "weighted avg       0.86      0.84      0.84       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(report_disruptor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "attribute = \"Black_Hair\"\n",
        "x = get_images_without_attr(celeba_loader, attribute, bb=False)\n",
        "x = x.cuda()\n",
        "c = torch.tensor([1, 0, 0, 0, 0])\n",
        "c = c.tile(100).view(100, 5).cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "P_ev = P.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = celeba_loader.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1999"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_100 = torch.zeros((100, 1, 3, 128, 128), device=\"cuda\")\n",
        "c_100 = torch.zeros((100, 1, 5), device=\"cuda\")\n",
        "x_fake = torch.zeros((100, 1, 3, 128, 128), device=\"cuda\")\n",
        "\n",
        "for i, (x, _) in enumerate(celeba_loader):\n",
        "    if i == 100:\n",
        "        break\n",
        "    x_100[i, 0] = x.cuda()\n",
        "    idx = torch.randint(low=0, high=len(ds), size=(1,)).item()\n",
        "    c = ds[idx][1].cuda()\n",
        "    c_100[i, 0] = c\n",
        "    x_fake[i, 0] = generate(x.cuda(), c.unsqueeze(0))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.007794022216796875\n"
          ]
        }
      ],
      "source": [
        "start.record()\n",
        "for i in range(100):\n",
        "    P(x_100[i])\n",
        "end.record()\n",
        "\n",
        "# Waits for everything to finish running\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print(start.elapsed_time(end) / 100 / 1000) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2134470703125\n"
          ]
        }
      ],
      "source": [
        "start.record()\n",
        "for i in range(100):\n",
        "    pgd_attack.perturb(x_100[i], x_fake[i], c_100[i])\n",
        "end.record()\n",
        "\n",
        "# Waits for everything to finish running\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print(start.elapsed_time(end) / 100 / 1000) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-6MZu9HLRDMW",
        "rjoFb5j-Q3kN"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "disruptor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "1040cd31433a2d294693187385b49a3d796dfcaee7f58efb4d68338a3af5edb2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
