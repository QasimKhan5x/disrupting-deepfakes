{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "import torchvision\n",
    "\n",
    "from ganimation.config import get_config\n",
    "from ganimation.data_loader import get_loader\n",
    "from ganimation.psolver import Disruptor\n",
    "\n",
    "from ganimation.attacks import LinfPGDAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Model configuration.\n",
    "parser.add_argument('--c_dim', type=int, default=17,\n",
    "                    help='dimension of domain labels')\n",
    "parser.add_argument('--image_size', type=int,\n",
    "                    default=128, help='image resolution')\n",
    "parser.add_argument('--g_conv_dim', type=int, default=64,\n",
    "                    help='number of conv filters in the first layer of G')\n",
    "parser.add_argument('--d_conv_dim', type=int, default=64,\n",
    "                    help='number of conv filters in the first layer of D')\n",
    "parser.add_argument('--g_repeat_num', type=int, default=6,\n",
    "                    help='number of residual blocks in G')\n",
    "parser.add_argument('--d_repeat_num', type=int, default=6,\n",
    "                    help='number of strided conv layers in D')\n",
    "parser.add_argument('--lambda_cls', type=float, default=160,\n",
    "                    help='weight for domain classification loss')\n",
    "parser.add_argument('--lambda_rec', type=float, default=10,\n",
    "                    help='weight for reconstruction loss')\n",
    "parser.add_argument('--lambda_gp', type=float, default=10,\n",
    "                    help='weight for gradient penalty')\n",
    "parser.add_argument('--lambda_sat', type=float, default=0.1,\n",
    "                    help='weight for attention saturation loss')\n",
    "parser.add_argument('--lambda_smooth', type=float, default=1e-4,\n",
    "                    help='weight for the attention smoothing loss')\n",
    "parser.add_argument('--eps', type=float, default=0.05, help='epsilon for perturbation')\n",
    "parser.add_argument('--order', type=int, default=2, help='distance metric')\n",
    "\n",
    "# Training configuration\n",
    "parser.add_argument('--seed', type=int, default=0,\n",
    "                    help='seed for experiments')\n",
    "parser.add_argument('--dataset', type=str, default='CelebA',\n",
    "                    choices=['CelebA', 'RaFD', 'Both'])\n",
    "parser.add_argument('--batch_size', type=int,\n",
    "                    default=32, help='mini-batch size')\n",
    "parser.add_argument('--epochs', type=int, default=30,\n",
    "                    help='number of total epochs for training P')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='learning rate for G')\n",
    "parser.add_argument('--beta1', type=float, default=0.99,\n",
    "                    help='beta1 for Adam optimizer')\n",
    "parser.add_argument('--beta2', type=float, default=0.999,\n",
    "                    help='beta2 for Adam optimizer')\n",
    "parser.add_argument('--resume', default=False,\n",
    "                    action='store_true', help='resume training from last epoch')\n",
    "parser.add_argument('--alpha', type=float, default=0.1,\n",
    "                    help=\"alpha for gradnorm\")\n",
    "parser.add_argument('--detector', type=str, default='xception', choices=['xception', 'resnet18', 'resnet50'])\n",
    "\n",
    "\n",
    "# Miscellaneous.\n",
    "parser.add_argument('--num_workers', type=int, default=48)\n",
    "parser.add_argument('--mode', type=str, default='train',\n",
    "                    choices=['train', 'animation'])\n",
    "parser.add_argument('--disable_tensorboard',\n",
    "                    action='store_true', default=False)\n",
    "parser.add_argument('--num_sample_targets', type=int, default=4,\n",
    "                    help=\"number of targets to use in the samples visualization\")\n",
    "\n",
    "# Directories.\n",
    "parser.add_argument('--gen_ckpt', type=str,\n",
    "                    default='ganimation/7001-37-G.ckpt')\n",
    "parser.add_argument('--detector_path', type=str,\n",
    "                    default='detection/detector_c23.pth')\n",
    "parser.add_argument('--image_dir', type=str,\n",
    "                    default='ganimation/data/celeba/images_aligned')\n",
    "parser.add_argument('--attr_path', type=str,\n",
    "                    default='ganimation/data/celeba/list_attr_celeba.txt')\n",
    "parser.add_argument('--outputs_dir', type=str, default='experiment1')\n",
    "parser.add_argument('--log_dir', type=str, default='logs')\n",
    "parser.add_argument('--model_save_dir', type=str, default='models')\n",
    "parser.add_argument('--sample_dir', type=str, default='samples')\n",
    "parser.add_argument('--result_dir', type=str, default='results')\n",
    "\n",
    "parser.add_argument('--animation_images_dir', type=str,\n",
    "                    default='data/celeba/images_aligned/new_small')\n",
    "parser.add_argument('--animation_attribute_images_dir', type=str,\n",
    "                    default='animations/eric_andre/attribute_images')\n",
    "parser.add_argument('--animation_attributes_path', type=str,\n",
    "                    default='animations/eric_andre/attributes.txt')\n",
    "parser.add_argument('--animation_models_dir', type=str,\n",
    "                    default='models')\n",
    "parser.add_argument('--animation_results_dir', type=str,\n",
    "                    default='out')\n",
    "parser.add_argument('--animation_mode', type=str, default='animate_image',\n",
    "                    choices=['animate_image', 'animate_random_batch'])\n",
    "\n",
    "# Step size.\n",
    "parser.add_argument('--log_step', type=int, default=1)\n",
    "parser.add_argument('--sample_step', type=int, default=1)\n",
    "\n",
    "config = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready!...\n",
      "------------------------------------------------\n",
      "Training images:  156295\n",
      "Testing images:  100\n"
     ]
    }
   ],
   "source": [
    "config.mode = \"test\"\n",
    "config.batch_size = 1\n",
    "\n",
    "data_loader = get_loader(config.image_dir, config.attr_path, config.c_dim,\n",
    "                        config.batch_size, config.mode, config.num_workers)\n",
    "# config_dict = vars(config)\n",
    "solver = Disruptor(config, data_loader).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = solver.P\n",
    "P.load_state_dict(torch.load(\"ganimation/experiments/experiment1_xception/models/best.ckpt\", map_location=\"cuda\"))\n",
    "\n",
    "G = solver.G\n",
    "D = solver.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_attack = LinfPGDAttack(model=G, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    \"\"\"Convert the range from [-1, 1] to [0, 1].\"\"\"\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp_(0, 1)\n",
    "\n",
    "\n",
    "def show_images(x):\n",
    "    images = denorm(x.cpu())\n",
    "    grid_img = torchvision.utils.make_grid(images, nrow=10)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imFromAttReg(att, reg, x_real):\n",
    "    \"\"\"Mixes attention, color and real images\"\"\"\n",
    "    return (1-att)*reg + att*x_real\n",
    "    \n",
    "@torch.no_grad()\n",
    "def generate(x_real, c_trg):\n",
    "    att, reg = G(x_real, c_trg)\n",
    "    x_fake = imFromAttReg(att, reg, x_real)\n",
    "    return x_fake\n",
    "\n",
    "def joint_class_attack(x_real, x_fake, c):\n",
    "    x_adv, perturb = pgd_attack.perturb(x_real, x_fake, c)\n",
    "    x_adv = x_real + perturb\n",
    "    return x_adv\n",
    "    \n",
    "@torch.no_grad()\n",
    "def detect(x):\n",
    "    output = D(x)\n",
    "    output = softmax(output, 1)\n",
    "    prediction = output.argmin(1, keepdim=False)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def perturb(x):\n",
    "    return P(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l2_distance(x_fake, xp_fake, num_imgs=100):\n",
    "    x_fake = x_fake.view(num_imgs, -1)\n",
    "    xp_fake = xp_fake.view(num_imgs, -1)\n",
    "    return torch.linalg.norm(x_fake - xp_fake, dim=1, ord=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(x, c):\n",
    "    xp = perturb(x)\n",
    "    x_fake = generate(x, c)\n",
    "    xp_fake = generate(xp, c)\n",
    "    x_adv = joint_class_attack(x, x_fake, c)\n",
    "    x_adv_fake = generate(x_adv, c)\n",
    "\n",
    "    predicted_real = detect(x).cpu().numpy()\n",
    "    # predicted_real_p = detect(xp).cpu().numpy()\n",
    "\n",
    "    predicted_fake = detect(x_fake).cpu().numpy()\n",
    "    predicted_fake_p = detect(xp_fake).cpu().numpy()\n",
    "    predicted_fake_adv = detect(x_adv_fake).cpu().numpy()\n",
    "\n",
    "    y_pred = np.hstack((predicted_real, predicted_fake))\n",
    "    # yp_pred = np.hstack((predicted_real_p, predicted_fake_p))\n",
    "    yp_pred = np.hstack((predicted_real, predicted_fake_p))\n",
    "    yadv_pred = np.hstack((predicted_real, predicted_fake_adv))\n",
    "    y_true = np.hstack((np.ones(100), np.zeros(100)))\n",
    "\n",
    "    report_ganimation = classification_report(\n",
    "        y_true, y_pred, target_names=[\"fake\", \"real\"])\n",
    "    report_pgd = classification_report(\n",
    "        y_true, yadv_pred, target_names=[\"fake\", \"real\"])\n",
    "    report_disruptor = classification_report(\n",
    "        y_true, yp_pred, target_names=[\"fake\", \"real\"])\n",
    "\n",
    "    return report_ganimation, report_pgd, report_disruptor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, c_org = iter(data_loader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda()\n",
    "c_org = c_org.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_trg = c_org[torch.randperm(c_org.size(0))].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_ganimation, report_pgd, report_disruptor = get_metrics(x, c_trg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report_ganimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report_pgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report_disruptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    show_images(generate(x, c_trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    show_images(perturb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_ev = P.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = data_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_100 = torch.zeros((100, 1, 3, 128, 128), device=\"cuda\")\n",
    "c_100 = torch.zeros((100, 1, 17), device=\"cuda\")\n",
    "x_fake = torch.zeros((100, 1, 3, 128, 128), device=\"cuda\")\n",
    "\n",
    "for i, (x, _) in enumerate(data_loader):\n",
    "    if i == 100:\n",
    "        break\n",
    "    x_100[i, 0] = x.cuda()\n",
    "    idx = torch.randint(low=0, high=len(ds), size=(1,)).item()\n",
    "    c = ds[idx][1].cuda()\n",
    "    c_100[i, 0] = c\n",
    "    x_fake[i, 0] = generate(x.cuda(), c.unsqueeze(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0078297802734375\n"
     ]
    }
   ],
   "source": [
    "start.record()\n",
    "for i in range(100):\n",
    "    P(x_100[i])\n",
    "end.record()\n",
    "\n",
    "# Waits for everything to finish running\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(start.elapsed_time(end) / 100 / 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23577623046875\n"
     ]
    }
   ],
   "source": [
    "start.record()\n",
    "for i in range(100):\n",
    "    pgd_attack.perturb(x_100[i], x_fake[i], c_100[i])\n",
    "end.record()\n",
    "\n",
    "# Waits for everything to finish running\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(start.elapsed_time(end) / 100 / 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disruptor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1040cd31433a2d294693187385b49a3d796dfcaee7f58efb4d68338a3af5edb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
